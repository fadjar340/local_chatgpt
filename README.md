# ðŸ“˜ Local ChatGPT â€“ Multi-Agent with OpenWebUI, Celery, and Ollama

This project sets up a **powerful local AI environment** using:

- **OpenWebUI** as the interface
- **Celery + Redis** as the task orchestration backend
- **Ollama** as the local LLM server (supports LLaMA3, LLaVA, etc.)
- **Extensions** for OCR, Graph Rendering, Research Fetcher, Smart Router, Logging, TeX Export, and more

---

## âœ… 1. Project Structure

local_chatgpt/
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile.openwebui
â”œâ”€â”€ entrypoint.sh # Ollama model auto-puller
â”œâ”€â”€ Makefile # Automation commands
â”œâ”€â”€ extensions/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ celery_config.py
â”‚ â”œâ”€â”€ worker_tasks.py # Celery task definitions
â”‚ â”œâ”€â”€ smart_router.py # Dynamic task routing
â”‚ â”œâ”€â”€ sql_logger.py # Project chat logging
â”‚ â”œâ”€â”€ sqlite_logger.py # Event logging
â”‚ â”œâ”€â”€ image_ocr.py # OCR using Tesseract
â”‚ â”œâ”€â”€ graph_renderer.py # Graph rendering with Matplotlib
â”‚ â”œâ”€â”€ research_fetcher.py # Research paper fetcher (arXiv API)
â”‚ â”œâ”€â”€ tex_export.py # TeX export
â”‚ â””â”€â”€ workers/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ math_agent.py
â”‚ â”œâ”€â”€ search_agent.py
â”‚ â”œâ”€â”€ pcb_agent.py
â”‚ â””â”€â”€ rag_agent.py
â””â”€â”€ data/
â””â”€â”€ (persistent data, logs, outputs)

---

## âœ… 2. Prerequisites

- Docker & Docker Compose installed
- At least **8GB RAM** (for LLaMA3 8B) or **more** (for larger models)
- Enough disk space for models (`./models` volume)

---

## âœ… 3. Quick Start

### ðŸ”¹ Build Images

```bash
make build

ðŸ”¹ Start All Services

make up

ðŸ”¹ Open WebUI

http://localhost:3000

## âœ… 4. Services Overview

Service Port Purpose
OpenWebUI 3000 Web interface
Ollama 11434 LLM model serving
Redis 6379 Celery broker
Celery Worker - Executes agent tasks

## âœ… 5. Ollama Model Configuration

```
Models are auto-pulled at container startup using entrypoint.sh.

To add more models:
```

export OLLAMA_MODELS="llama3:8b-q4_K_M llama3:70b llava:13b-q4 mistral:7b"
make restart

## âœ… 6. Features

### âœ… Multi-Agent System:

```
math_agent â†’ handles mathematical calculations

search_agent â†’ performs web search

pcb_agent â†’ runs KiCad PCB analysis

rag_agent â†’ queries RAG database

ocr_agent â†’ extracts text from images

graph_agent â†’ renders graphs

research_agent â†’ fetches research papers

router_agent â†’ routes tasks dynamically

logger_agent â†’ logs events to SQLite

tex_export_agent â†’ exports TeX files
```

### âœ… Project-Aware Logging:

```
Logs chat context per project

Stores data in /app/logs/chat_logs.db
```

### âœ… Smart Router:

```
Dynamically dispatches tasks to correct agents
```

### âœ… Celery + Redis Backend:

```
Asynchronous task handling

Scalable worker architecture
```

## âœ… 7. Makefile Commands

Command Description
make build Build all Docker images
make up Start all services
make down Stop all services
make restart Restart the stack
make logs View logs for OpenWebUI + Celery
make logs-ui View only OpenWebUI logs
make logs-celery View only Celery worker logs
make logs-ollama View only Ollama logs
make shell-ui Enter OpenWebUI container
make shell-worker Enter Celery Worker container
make shell-ollama Enter Ollama container
make clean Prune unused Docker images/volumes
make test-math Test math agent via Celery

## âœ… 8. Testing Celery Agents

Example: Test math agent directly:

make test-math

Expected output:

ðŸ§® Math Agent Result:
4

## âœ… 9. Logs & Project Context

```
Chat logs: /app/logs/chat_logs.db

Event logs: /app/data/events.db
```

Query logs via Celery task:

docker exec -it celery-worker celery call logger_agent.fetch_logs --args='["RMFE_Main", 5]'

## âœ… 10. Adding New Agents

```
Create a new file in extensions/workers/

Define a function that handles logic

Register it in worker_tasks.py

(Optional) Add routing in smart_router.py

Rebuild and restart:
```

make restart

ðŸš€ Youâ€™re Ready!

With this setup:

```
âœ… You have OpenAI-like multi-agent ChatGPT running locally

âœ… Ollama handles model inference

âœ… Celery coordinates asynchronous tasks

âœ… Logs and project contexts are fully supported
```

ðŸ”¥ Next Upgrade Ideas:

```
Multi-project RAG databases

Distributed workers (Raspberry Pi integration)

Auto-summary of logs per project
```
